{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./winequality_red.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target attribute\n",
    "target_name = 'quality'\n",
    "target = df[target_name]\n",
    "\n",
    "# predictor attributes\n",
    "predictors = df.drop(target_name, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pepare independent stratified data sets for training and test of the final model\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(\n",
    "    predictors, target, test_size=0.20, shuffle=True, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "predictors_train = min_max_scaler.fit_transform(predictors_train)\n",
    "predictors_test = min_max_scaler.fit_transform(predictors_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Apply RFE with SVM for selecting the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False False False False False False  True  True]\n",
      "[5 1 9 4 2 7 3 6 8 1 1]\n"
     ]
    }
   ],
   "source": [
    "# create a base classifier used to evaluate a subset of attributes\n",
    "estimatorSVM = svm.SVR(kernel=\"linear\")\n",
    "selectorSVM = RFE(estimatorSVM, 3)\n",
    "selectorSVM = selectorSVM.fit(predictors_train, target_train)\n",
    "# summarize the selection of the attributes\n",
    "print(selectorSVM.support_)\n",
    "print(selectorSVM.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Apply RFE with Logistic Regression for selecting the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False False False False False False  True  True]\n",
      "[3 1 6 5 7 8 2 4 9 1 1]\n"
     ]
    }
   ],
   "source": [
    "# create a base classifier used to evaluate a subset of attributes\n",
    "estimatorLR = LogisticRegression(solver = 'lbfgs', multi_class='auto')\n",
    "# create the RFE model and select 3 attributes\n",
    "selectorLR = RFE(estimatorLR, 3)\n",
    "selectorLR = selectorLR.fit(predictors_train, target_train)\n",
    "# summarize the selection of the attributes\n",
    "print(selectorLR.support_)\n",
    "print(selectorLR.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Evaluate on the Test Data Set\n",
    "Apply the selectors to prepare training data sets only with the selected features\n",
    "Note: The same selectors are applied to the test data set. However, it is important that the test data set was not used by (it's invisible to) the selectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train_SVMselected = selectorSVM.transform(predictors_train)\n",
    "predictors_test_SVMselected = selectorSVM.transform(predictors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train_LRselected = selectorLR.transform(predictors_train)\n",
    "predictors_test_LRselected = selectorLR.transform(predictors_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate SVM classifiers with both the selected features and all features \n",
    "\n",
    "Here we train three models:\n",
    "* model1 - with the features selected by SVM\n",
    "* model2 - with the features selected by Logistic Regression\n",
    "* model3 - with all features (i.e. without feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC(gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.571875"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = classifier.fit(predictors_train_SVMselected, target_train)\n",
    "model1.score(predictors_test_SVMselected, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.571875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = classifier.fit(predictors_train_LRselected, target_train)\n",
    "model2.score(predictors_test_LRselected, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.584375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = classifier.fit(predictors_train, target_train)\n",
    "model3.score(predictors_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Conclusion\n",
    "\n",
    "When you execute this code again, it is very likely to get different results.\n",
    "\n",
    "To get more accurate results, accounting for the variance in the results, it is better to run the whole experiment multiple times and measure the variance in the results. Then pick the model that gives better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Loop de Loop and Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task3():\n",
    "    # pepare independent stratified data sets for training and test of the final model\n",
    "    predictors_train, predictors_test, target_train, target_test = train_test_split(\n",
    "    predictors, target, test_size=0.20, shuffle=True, stratify=target)\n",
    "    \n",
    "    # scale values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    predictors_train = min_max_scaler.fit_transform(predictors_train)\n",
    "    predictors_test = min_max_scaler.fit_transform(predictors_test)\n",
    "    \n",
    "    ### RFE with SVM ###\n",
    "    # create a base classifier used to evaluate a subset of attributes\n",
    "    estimatorSVM = svm.SVR(kernel=\"linear\")\n",
    "    selectorSVM = RFE(estimatorSVM, 3)\n",
    "    selectorSVM = selectorSVM.fit(predictors_train, target_train)\n",
    "    predictors_train_SVMselected = selectorSVM.transform(predictors_train)\n",
    "    predictors_test_SVMselected = selectorSVM.transform(predictors_test)\n",
    "    \n",
    "    ### RFE with LR ###\n",
    "    # create a base classifier used to evaluate a subset of attributes\n",
    "    estimatorLR = LogisticRegression(solver = 'lbfgs', multi_class='auto')\n",
    "    # create the RFE model and select 3 attributes\n",
    "    selectorLR = RFE(estimatorLR, 3)\n",
    "    selectorLR = selectorLR.fit(predictors_train, target_train)\n",
    "    predictors_train_LRselected = selectorLR.transform(predictors_train)\n",
    "    predictors_test_LRselected = selectorLR.transform(predictors_test)\n",
    "    \n",
    "    ### Train and Evaluate Classifiers ###\n",
    "    classifier = svm.SVC(gamma='scale')\n",
    "    \n",
    "    model1 = classifier.fit(predictors_train_SVMselected, target_train)\n",
    "    score_SVC = model1.score(predictors_test_SVMselected, target_test)\n",
    "    \n",
    "    model2 = classifier.fit(predictors_train_LRselected, target_train)\n",
    "    score_LR = model2.score(predictors_test_LRselected, target_test)\n",
    "    \n",
    "    model3 = classifier.fit(predictors_train, target_train)\n",
    "    score_NA = model3.score(predictors_test, target_test)\n",
    "    \n",
    "    return score_SVC, score_LR, score_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVC</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>NA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.568500</td>\n",
       "      <td>0.568563</td>\n",
       "      <td>0.570594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023938</td>\n",
       "      <td>0.022083</td>\n",
       "      <td>0.024308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.503125</td>\n",
       "      <td>0.503125</td>\n",
       "      <td>0.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.556250</td>\n",
       "      <td>0.556250</td>\n",
       "      <td>0.553125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.568750</td>\n",
       "      <td>0.571875</td>\n",
       "      <td>0.571875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>0.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.653125</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.640625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SVC  Logistic Regression          NA\n",
       "count  100.000000           100.000000  100.000000\n",
       "mean     0.568500             0.568563    0.570594\n",
       "std      0.023938             0.022083    0.024308\n",
       "min      0.503125             0.503125    0.484375\n",
       "25%      0.556250             0.556250    0.553125\n",
       "50%      0.568750             0.571875    0.571875\n",
       "75%      0.584375             0.584375    0.587500\n",
       "max      0.653125             0.612500    0.640625"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_SVC = np.array([])\n",
    "scores_LR = np.array([])\n",
    "scores_NA = np.array([])\n",
    "\n",
    "for i in range(0,100):\n",
    "    a, b, c = task3()\n",
    "    scores_SVC = np.append(scores_SVC, a)\n",
    "    scores_LR = np.append(scores_LR, b)\n",
    "    scores_NA = np.append(scores_NA, c)\n",
    "\n",
    "scores_df = pd.DataFrame(data={'SVC' : scores_SVC, 'Logistic Regression' : scores_LR, 'NA' : scores_NA})\n",
    "scores_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1af15748>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores_df.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conlclusion\n",
    "After running 100 iterations of each feature selection method, it's clear that there isn't much between them. \n",
    "\n",
    "In fact, the highest average mean was held by using no feature selection at all! SVM achieved the highest max score, indicating it may have the most potential. Meanwhile, Logistic Regression has the lowest standard deviation, suggesting it's the most consistent. \n",
    "\n",
    "My instict would be to go for Logistic Regression as the best method here, but it's hard to say for sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "df = pd.read_csv(\"./winequality_red.csv\")\n",
    "x=df.drop(['quality'],axis=1)\n",
    "y=df['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', preprocessing.MinMaxScaler()), ('SVM', svm.SVC())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=30, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'SVM__C':[0.001,0.1,10,100,10e5], 'SVM__gamma':[0.1,0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipeline, param_grid=parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.61\n",
      "{'SVM__C': 1000000.0, 'SVM__gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "print(\"score = %3.2f\" %(grid.score(X_test,y_test)))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(preprocessing.MinMaxScaler(), LogisticRegression(solver='lbfgs', multi_class='auto'))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=30, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'logisticregression__C':[0.001,0.1,10,100,1000,10e5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipeline, parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.59\n",
      "{'logisticregression__C': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "print(\"score = %3.2f\" %(grid.score(X_test,y_test)))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used pipelines with SVM and Logistic Regression feature selection, and similar to my above results, there isn't a huge difference.\n",
    "\n",
    "However, SVM did score slightly higher (0.61 vs 0.59) and so I would nominate that as the better model in this case. It is worth noting that the SVM version took much longer to run, compared with Logistic Regression, but I don't think that's enough of a reason to ignore the better results.\n",
    "\n",
    "P.S. Please forgive the numerous ConvergenceWarnings, I did search this and some solutions were offered, but they also noted that it may just be a natural consequence of the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
